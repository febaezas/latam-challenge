{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 TE Conteo ##\n",
    "\n",
    "este acercamiento (lectura completa del archivo y luego trabajar sobre el) era la idea principal a ejecutar en las tareas de tiempo, buscando optimizar y luego al ver opciones para la ejecucion por memoria se intento por chunks o lotes iterando, idea principal para aplica en challenge de consumo de memoria pero tambien efecta el tiempo de ejecucion, se podria revisar en hacer solo por streaming o bajar el chunk size para ver si se optimiza mas ram, pero al ajustarlo demasiado agrandaria el merge con agrupaciones mas inconsistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Timestamp('2021-02-12 00:00:00+0000', tz='UTC'), 'RanbirS00614606'), (Timestamp('2021-02-13 00:00:00+0000', tz='UTC'), 'MaanDee08215437'), (Timestamp('2021-02-17 00:00:00+0000', tz='UTC'), 'RaaJVinderkaur'), (Timestamp('2021-02-16 00:00:00+0000', tz='UTC'), 'jot__b'), (Timestamp('2021-02-14 00:00:00+0000', tz='UTC'), 'rebelpacifist'), (Timestamp('2021-02-18 00:00:00+0000', tz='UTC'), 'neetuanjle_nitu'), (Timestamp('2021-02-15 00:00:00+0000', tz='UTC'), 'jot__b'), (Timestamp('2021-02-20 00:00:00+0000', tz='UTC'), 'MangalJ23056160'), (Timestamp('2021-02-23 00:00:00+0000', tz='UTC'), 'Surrypuria'), (Timestamp('2021-02-19 00:00:00+0000', tz='UTC'), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "## Se considera utilizar CUDA para aprovechar GPU en manejo de pandas dataframes tanto local como docker https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes/\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q1_time import q1_time\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "#%memit a = q1_time(file_path)\n",
    "#%memit q1_time(file_path)\n",
    "print (q1_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Memory\n",
    "Considera procesar datos por chunks, para optimizar uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 588.14 MiB, increment: 438.29 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "## Se considera utilizar CUDA para aprovechar GPU en manejo de pandas dataframes tanto local como docker https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes/\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q1_memory import q1_memory\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "#%memit a = q1_time(file_path)\n",
    "%memit print(q1_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Tiempo ejecucion para etraer emojis ##\n",
    "\n",
    "Se carga json y luego se usa de paquete espeficico para emojis para filtrar y contar cuantas veces aparecen en los comentarios.\n",
    "en teoria una lectura directa del .json es mas rapida que lectura por lotes. pero eso dependera igual de la carga logica (cuanto calculo hare vs el tiempo en cargarlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n",
      "peak memory: 2771.15 MiB, increment: 2328.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q2_time import q2_time\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "%memit print(q2_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Memoria para extraer emoji\n",
    "\n",
    "Se itera la lectura del json file igual que en ejercicio anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972), ('üåæ', 2182), ('üáÆüá≥', 2086), ('ü§£', 1668), ('‚úä', 1651), ('‚ù§Ô∏è', 1382), ('üôèüèª', 1317), ('üíö', 1040)]\n",
      "peak memory: 680.58 MiB, increment: 524.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q2_memory import q2_memory\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "%memit print(q2_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 TE menciones ###\n",
    "\n",
    "Se usa regex en comentarios para contar interacciones\n",
    "     Por mejorar:\n",
    "     \n",
    "       - Se hace conteo solo de menciones en tweets para medir impacto\n",
    "       - no considera citas para ver efecto cascada del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio iteracion\n",
      "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1639), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n",
      "peak memory: 693.04 MiB, increment: 541.09 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "## Se considera utilizar CUDA para aprovechar GPU en manejo de pandas dataframes tanto local como docker https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes/\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q3_time import q3_time\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "#%memit a = q1_time(file_path)\n",
    "%memit print(q3_time(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Memoria Menciones\n",
    "\n",
    "Misma idea que ejercicios anteriores, para optimizar memoria se trabaja por chunks y con regex para extraer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "## Se considera utilizar CUDA para aprovechar GPU en manejo de pandas dataframes tanto local como docker https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes/\n",
    "# %load_ext cudf.pandas\n",
    "\n",
    "from q3_memory import q3_memory\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "#%memit a = q1_time(file_path)\n",
    "%memit print(q3_memory(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
